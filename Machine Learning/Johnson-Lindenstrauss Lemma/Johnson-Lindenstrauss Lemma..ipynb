{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment04Q5.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "PROBLEM 5"
      ],
      "metadata": {
        "id": "OFt1fwt-zG0i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Nja8TrMDwcmx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "from sklearn.random_projection import GaussianRandomProjection\n",
        "from sklearn.random_projection import johnson_lindenstrauss_min_dim"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.1 Here we are creating matrix as m_2, as per the given question we create a identity matrix with number of columns of 10 and with 5000 d."
      ],
      "metadata": {
        "id": "VUX6K9C903xe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m_1= np.identity(5000)\n",
        "m_x= m_1[0:10,:]\n",
        "m_x[0:5,:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xy7gQphSwkrF",
        "outputId": "c03aad33-a1fd-43f8-c504-2a50b59c0f21"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 1., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dimensions = len(m_x[1])\n",
        "print('The Dimensions of matrix',dimensions)\n",
        "nocol =len(m_x)\n",
        "print('The  number of columns in the matrix is',nocol)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5Vr4__hwsog",
        "outputId": "ab0f17dc-e7d3-4335-e87f-120887f51e47"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Dimensions of matrix 5000\n",
            "The  number of columns in the matrix is 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we have to calualate the  embedding\n",
        "dimension m by plugging in the formula, code below describe the embedding"
      ],
      "metadata": {
        "id": "N0TP1wLn3OMj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m=johnson_lindenstrauss_min_dim(n_samples=10, eps=0.1)\n",
        "print('The embedding dimension is',m)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sx-9cw45xfL6",
        "outputId": "334ee903-ec1a-49fd-c94d-11ae0b0013e3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The embedding dimension is 1973\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.2 Now, we need to Construct a random projection matrix A of size m Ã— d "
      ],
      "metadata": {
        "id": "2OBDw6i15Q-R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "projections = GaussianRandomProjection()\n",
        "projectionsmatrixA = projections.fit_transform(m_x)\n",
        "print('Shape of projectionsmatrix is :',(projectionsmatrixA.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xoF0vpBH4kqd",
        "outputId": "37a6d4bc-fbe2-4b3d-b46f-3f3137a0d4d5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of projectionsmatrix is : (10, 1973)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, Compare distances in m_2 with the distances between the projectionsmatrix, For the we can use the Eculidean distiance \n"
      ],
      "metadata": {
        "id": "CwPRGAut7i1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "distancem_x = euclidean_distances(m_x)\n",
        "distanceprojectionsmatrixA = euclidean_distances(projectionsmatrixA)\n",
        "diff_distance = abs(distancem_x - distanceprojectionsmatrixA)\n",
        "diff_distance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evqqZroT8KSt",
        "outputId": "b333a5a0-ddd5-442a-e7ee-5552c50023ef"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.00000000e+00, 1.14471151e-02, 3.11164774e-03, 1.62531041e-02,\n",
              "        2.36090547e-02, 1.35051450e-02, 4.59222057e-03, 9.46303561e-03,\n",
              "        7.96699199e-03, 2.40770877e-02],\n",
              "       [1.14471151e-02, 0.00000000e+00, 1.92310104e-02, 1.29418928e-02,\n",
              "        1.03195137e-02, 1.13160229e-02, 2.71825902e-02, 2.55099292e-02,\n",
              "        1.84366397e-02, 1.28875038e-02],\n",
              "       [3.11164774e-03, 1.92310104e-02, 0.00000000e+00, 1.32679712e-02,\n",
              "        2.32915480e-02, 6.76472537e-03, 2.38256095e-02, 1.62027590e-02,\n",
              "        2.26072460e-02, 7.88392917e-03],\n",
              "       [1.62531041e-02, 1.29418928e-02, 1.32679712e-02, 0.00000000e+00,\n",
              "        3.96975148e-04, 1.27980388e-02, 1.87217148e-03, 1.54909173e-02,\n",
              "        1.00477163e-02, 2.80541240e-03],\n",
              "       [2.36090547e-02, 1.03195137e-02, 2.32915480e-02, 3.96975148e-04,\n",
              "        0.00000000e+00, 1.77967876e-02, 2.78368554e-03, 1.66550483e-02,\n",
              "        1.47439876e-02, 1.34410497e-02],\n",
              "       [1.35051450e-02, 1.13160229e-02, 6.76472537e-03, 1.27980388e-02,\n",
              "        1.77967876e-02, 0.00000000e+00, 2.70971406e-05, 1.60931755e-02,\n",
              "        3.36329875e-02, 2.58636496e-02],\n",
              "       [4.59222057e-03, 2.71825902e-02, 2.38256095e-02, 1.87217148e-03,\n",
              "        2.78368554e-03, 2.70971406e-05, 0.00000000e+00, 6.88664480e-03,\n",
              "        2.96431894e-02, 1.49008482e-03],\n",
              "       [9.46303561e-03, 2.55099292e-02, 1.62027590e-02, 1.54909173e-02,\n",
              "        1.66550483e-02, 1.60931755e-02, 6.88664480e-03, 0.00000000e+00,\n",
              "        4.10585669e-03, 2.47427105e-03],\n",
              "       [7.96699199e-03, 1.84366397e-02, 2.26072460e-02, 1.00477163e-02,\n",
              "        1.47439876e-02, 3.36329875e-02, 2.96431894e-02, 4.10585669e-03,\n",
              "        0.00000000e+00, 2.49108920e-02],\n",
              "       [2.40770877e-02, 1.28875038e-02, 7.88392917e-03, 2.80541240e-03,\n",
              "        1.34410497e-02, 2.58636496e-02, 1.49008482e-03, 2.47427105e-03,\n",
              "        2.49108920e-02, 0.00000000e+00]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " for every pair of data points, is the projection distance is within 10% of the original distance , we can do the comparison by taking the length of matrix x staring point to length of matrix x, we can use them as the looping constants and we can take the distance of data point matrix A which is comapared with distance of matrix x *0.9 and also we campare same with distance matrix x *1.10, by this we can say Johnson-Lindenstrauss Lemma is holding or not."
      ],
      "metadata": {
        "id": "WzozOnTW_zAD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,len(distancem_x)):\n",
        "  for j in range(0,len(distancem_x[0])):\n",
        "    if (distanceprojectionsmatrixA[i][j] >= distancem_x[i][j]*0.9) and (distanceprojectionsmatrixA[i][j] <= distancem_x[i][j]*1.10):\n",
        "      verification=\"Johnson Lindenstrauss Lemma is holding\"\n",
        "    else:\n",
        "      verification=\"Johnson Lindenstrauss Lemma is not holding\"\n",
        "print(verification)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9AgPJgD-qtH",
        "outputId": "fed959f4-1d6f-42b8-8459-d86417b13f00"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Johnson Lindenstrauss Lemma is holding\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.3 Now, Repeat the above steps by increasing d as a factor 2 each time with m and n fixed."
      ],
      "metadata": {
        "id": "CBuMVpBZCSWq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So now, we can use loop throught above process until your system runs out of memory with inital d=5000"
      ],
      "metadata": {
        "id": "XvkzlFCYCcy7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "k = 5000\n",
        "while 1:\n",
        "  k = k * 2\n",
        "  m_1= np.identity(k)\n",
        "  m_x= m_1[0:10,:]\n",
        "  m_x[0:5,:]\n",
        "  dimensions = len(m_x[1])\n",
        "  print('The dimension of the matrix',dimensions)\n",
        "  nocol =len(m_x)\n",
        "  print('The  number of columns in the matrix is',nocol)\n",
        "  m=johnson_lindenstrauss_min_dim(n_samples=10, eps=0.1)\n",
        "  print('The embedding dimension is',m)\n",
        "  projections = GaussianRandomProjection()\n",
        "  projectionsmatrixA = projections.fit_transform(m_x)\n",
        "  distancem_x = euclidean_distances(m_x)\n",
        "  distanceprojectionsmatrixA = euclidean_distances(projectionsmatrixA)\n",
        "  diff_distance = abs(distancem_x - distanceprojectionsmatrixA)\n",
        "  for i in range(0,len(distancem_x)):\n",
        "    for j in range(0,len(distancem_x[0])):\n",
        "      if (distanceprojectionsmatrixA[i][j] >= distancem_x[i][j]*0.9) and (distanceprojectionsmatrixA[i][j] <= distancem_x[i][j]*1.10):\n",
        "        verification=\"Johnson Lindenstrauss Lemma is holding\"\n",
        "      else:\n",
        "        verification=\"Johnson Lindenstrauss Lemma is not holding\"\n",
        "  print('For',k ,verification)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-JWFJ-oCZct",
        "outputId": "b0af9060-0a2a-4800-85dc-b5beca4c9d06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The dimension of the matrix 10000\n",
            "The  number of columns in the matrix is 10\n",
            "The embedding dimension is 1973\n",
            "For 10000 Johnson Lindenstrauss Lemma is holding\n",
            "The dimension of the matrix 20000\n",
            "The  number of columns in the matrix is 10\n",
            "The embedding dimension is 1973\n",
            "For 20000 Johnson Lindenstrauss Lemma is holding\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above output, we can say that for d=40000 Johnson Lindestrauss Lemma is not holding, that is why it is not printing in the above output. Hence by that we are verifiying the Lemma for each case from the above."
      ],
      "metadata": {
        "id": "UHslHWYTPFMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.4, Now we are keep on incerasing the number of columns n until system runs out of memory, so we can use a looping method to run the above method every time with n factor of 2"
      ],
      "metadata": {
        "id": "9pLqSAmHSXNR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "k = 5000\n",
        "q = 10\n",
        "while 1:\n",
        "  q = q * 2\n",
        "  m_1= np.identity(k)\n",
        "  m_x= m_1[0:q,:]\n",
        "  m_x[0:5,:]\n",
        "  dimensions = len(m_x[1])\n",
        "  print('The dimension of the matrix',dimensions)\n",
        "  nocol =len(m_x)\n",
        "  print('The  number of columns in the matrix is',nocol)\n",
        "  m=johnson_lindenstrauss_min_dim(n_samples=10, eps=0.1)\n",
        "  print('The embedding dimension is',m)\n",
        "  projections = GaussianRandomProjection()\n",
        "  projectionsmatrixA = projections.fit_transform(m_x)\n",
        "  distancem_x = euclidean_distances(m_x)\n",
        "  distanceprojectionsmatrixA = euclidean_distances(projectionsmatrixA)\n",
        "  diff_distance = abs(distancem_x - distanceprojectionsmatrixA)\n",
        "  for i in range(0,len(distancem_x)):\n",
        "    for j in range(0,len(distancem_x[0])):\n",
        "      if (distanceprojectionsmatrixA[i][j] >= distancem_x[i][j]*0.9) and (distanceprojectionsmatrixA[i][j] <= distancem_x[i][j]*1.10):\n",
        "        verification=\"Johnson Lindenstrauss Lemma is holding\"\n",
        "      else:\n",
        "        verification=\"Johnson Lindenstrauss Lemma is not holding\"\n",
        "  print('For',k ,verification)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 780
        },
        "id": "xaIb4SNBP6Pm",
        "outputId": "03b56bb6-90a2-41be-f639-c6430e373e89"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The dimension of the matrix 5000\n",
            "The  number of columns in the matrix is 20\n",
            "The embedding dimension is 1973\n",
            "For 5000 Johnson Lindenstrauss Lemma is holding\n",
            "The dimension of the matrix 5000\n",
            "The  number of columns in the matrix is 40\n",
            "The embedding dimension is 1973\n",
            "For 5000 Johnson Lindenstrauss Lemma is holding\n",
            "The dimension of the matrix 5000\n",
            "The  number of columns in the matrix is 80\n",
            "The embedding dimension is 1973\n",
            "For 5000 Johnson Lindenstrauss Lemma is holding\n",
            "The dimension of the matrix 5000\n",
            "The  number of columns in the matrix is 160\n",
            "The embedding dimension is 1973\n",
            "For 5000 Johnson Lindenstrauss Lemma is holding\n",
            "The dimension of the matrix 5000\n",
            "The  number of columns in the matrix is 320\n",
            "The embedding dimension is 1973\n",
            "For 5000 Johnson Lindenstrauss Lemma is holding\n",
            "The dimension of the matrix 5000\n",
            "The  number of columns in the matrix is 640\n",
            "The embedding dimension is 1973\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-b7172f64ed58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The embedding dimension is'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0mprojections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGaussianRandomProjection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m   \u001b[0mprojectionsmatrixA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprojections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m   \u001b[0mdistancem_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meuclidean_distances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0mdistanceprojectionsmatrixA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meuclidean_distances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprojectionsmatrixA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    850\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    851\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 852\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    853\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/random_projection.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    365\u001b[0m                     \u001b[0;34m\"%d which is larger than the original space with \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m                     \u001b[0;34m\"n_features=%d\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m                     \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_components_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m                 )\n\u001b[1;32m    369\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: eps=0.100000 and n_samples=640 lead to a target dimension of 5538 which is larger than the original space with n_features=5000"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see from the above that system run out of memory, Hence by that we can say that  Johnson-Lindenstrauss Lemma is holding"
      ],
      "metadata": {
        "id": "U3QbJ6Z3SyGz"
      }
    }
  ]
}